・モデルはどうする？
→ＬＳＴＭ
　＊dropout指定可能
　＊lstmを複数重ねる場合は最後のlstm層以外return_seqenceはtrue
・正規化する？
→０〜１の間に正規化する。

・層の数は？
→とりあえず１層

・ユニットの数は？
　→2^nで徐々に上げる

・活性化関数は？
→とりあえず線形

・look_backの数は？
→とりあえず３

・バッチサイズは？
＝＞とりあえずデフォルト
・正則化する？(過学習を抑えるため)
　L1,L2,early stopping,dropout,batch normalization

・最適化関数は？
　sgd, rmsprop, adagrad, adadelta, adam, adamax, nadam


・学習率は？
→１からはじめ、1/10, 1/100としていく
・損失関数は？
→ＭＳＥ

・エポック数は？
→100くらい？

